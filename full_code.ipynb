{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "698ef4c2-d362-4a99-bba8-f644fae6e636",
   "metadata": {},
   "source": [
    "# Creating the dictionary graph from raw csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8817d374-175a-4745-9155-647c6590031f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating nodes: 100%|██████████| 786333/786333 [00:17<00:00, 46175.68it/s]\n",
      "Processing routes: 100%|██████████| 1693/1693 [00:46<00:00, 36.63it/s] \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "path = \"routes_master_data.csv\"\n",
    "df = pd.read_csv(path)\n",
    "graph = {}\n",
    "# Initiating the graph\n",
    "for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Creating nodes\"):\n",
    "    stop_id = row['StopPlace Name']\n",
    "    if stop_id not in graph:\n",
    "        graph[stop_id] = {\n",
    "            'neighbors': {},  # Initialize an empty dictionary for neighbors\n",
    "            'latitude': row['StopPlace Latitude'],  # Get the stop latitude\n",
    "            'longitude': row['StopPlace Longitude'],  # Get the stop longitude\n",
    "        }\n",
    "\n",
    "# Second pass: Add connections between nodes\n",
    "# Group the DataFrame by Route ID\n",
    "grouped = df.groupby('Route_ID')\n",
    "\n",
    "# Iterate over each route\n",
    "for route_id, route_df in tqdm(grouped, total=len(grouped), desc=\"Processing routes\"):\n",
    "    # Sort the route DataFrame by Order\n",
    "    route_df = route_df.sort_values('Order')\n",
    "    \n",
    "    # Iterate over each pair of consecutive stops in the route\n",
    "    for i in range(len(route_df) - 1):\n",
    "        current_stop = route_df.iloc[i]\n",
    "        next_stop = route_df.iloc[i+1]\n",
    "        \n",
    "        current_id = current_stop['StopPlace Name']\n",
    "        next_id = next_stop['StopPlace Name']\n",
    "        \n",
    "        # Avoid self-loops\n",
    "        if current_id != next_id:\n",
    "            if next_id not in graph[current_id]['neighbors']:\n",
    "                graph[current_id]['neighbors'][next_id] = {\n",
    "                    'longitude': current_stop['StopPlace Longitude'], \n",
    "                    'latitude': current_stop['StopPlace Latitude'], \n",
    "                    'transport_mode': current_stop['TransportMode']\n",
    "                }\n",
    "                \n",
    "with open('graph_with_coordinates_and_neighbors.pickle', 'wb') as file:\n",
    "    pickle.dump(graph, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b189a8-b3bd-43f1-a4fb-d62fb7168636",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# System prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6da3aae-011a-42db-b0fe-28356dfdd334",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt1 = \"\"\"Evaluate the scenic and visual characteristics of public transport stops in Stockholm based on their name, season, surroundings, and notable features.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "\t1.\tDescribe surroundings and features with balanced, factual observations. Highlight both positives and negatives constructively. Avoid scoring or biased language.\n",
    "\t2.\tFocus on:\n",
    "\t•\tNeighborhood/District: Characterize the area’s vibe (e.g., residential, historic) and its scenic impact.\n",
    "\t•\tSurroundings: Mention landmarks, natural features, urban cleanliness, safety, or neglect.\n",
    "\t•\tAccessibility: Highlight features like signage, seating, and wheelchair access.\n",
    "\t•\tCultural/Historical Context: Note any relevant importance.\n",
    "\t•\tPublic Perception: Assess if it’s popular among locals or tourists or isolated.\n",
    "\t•\tComparative Context: Describe how it stands out or falls short compared to nearby stops.\n",
    "\t3.\tInclude negative features explicitly (e.g., industrial surroundings, poor lighting, unsafe areas).\n",
    "\t4.\tIf data is missing (e.g., no landmarks), state it clearly without guessing.\n",
    "\t5.\tEnsure descriptions are consistent across transport types and avoid redundancy.\n",
    "\t6.\tConsider seasonal variations (e.g., winter vs. summer scenery).\n",
    "\t7.\tEvaluate the stop’s appeal to tourists and explorers based on access, surroundings, and proximity to attractions.\n",
    "\"\"\"\n",
    "\n",
    "system_prompt2 = \"\"\"You are tasked with evaluating the scenic value of a public transport stop in Stockholm based on a detailed description. Assign a score from 0 to 10 by considering the following:\n",
    "\t1.\tKey Elements:\n",
    "\t•\tStop Name: Identify the stop being evaluated.\n",
    "\t•\tSeason: Assess how the current season impacts scenic appeal.\n",
    "\t•\tSurroundings: Note nearby landmarks, nature, or urban features.\n",
    "\t•\tAccessibility: Consider ease of access and its influence on appeal.\n",
    "\t2.\tScenic Value Scale:\n",
    "\t•\t0: Extremely unattractive (e.g., industrial, poorly maintained areas).\n",
    "\t•\t5: Average appeal (functional but unremarkable).\n",
    "\t•\t10: Iconic or uniquely scenic (e.g., waterfront views, exceptional design).\n",
    "\t3.\tBalancing Factors:\n",
    "\t•\tPositive Features: Highlight views, pleasant surroundings, or unique attributes.\n",
    "\t•\tNegative Factors: Prioritize significant drawbacks (e.g., poor maintenance) in scoring.\n",
    "\t•\tSeasonality: While seasonal changes matter, water stops should generally score higher.\n",
    "\t4.\tConsistency: Be realistic and critical when negative elements dominate.\n",
    "\n",
    "The final score should reflect a balanced, nuanced judgment of the stop’s scenic appeal.\n",
    "\n",
    "### Example Input Description:\n",
    "The stop name is 'Arlanda'. It is located in an airport complex, surrounded by large parking lots and commercial buildings. The surroundings\n",
    "feel quite sterile, with little to no greenery. During the winter, the area is gray and cold, and there is not much to see other than the\n",
    "airport itself.\n",
    "\n",
    "### Example Output:\n",
    "- **Scenic Value**: 3\n",
    "\n",
    "### Explanation:\n",
    "- The description highlights an **unattractive environment** with **industrial surroundings**, lack of greenery, and a **sterile** atmosphere.\n",
    "Winter's grayness and cold further detract from the visual appeal, leading to a low score.\n",
    "\n",
    "### Example Input Description:\n",
    "The stop name is 'Solna Centrum'. The station is located in a modern urban setting with a lot of open space, several nearby cafés, and some\n",
    "green patches. It feels clean and well-maintained, and during the spring, flowers bloom around the area.\n",
    "\n",
    "### Example Output:\n",
    "- **Scenic Value**: 7\n",
    "\n",
    "### Explanation:\n",
    "- The description mentions **modern urban features** with **open space**, **cafés**, and **green patches**. The **seasonal appeal** of spring\n",
    "adds to the overall scenic experience, but the setting isn't particularly striking or unique. Still, it is **clean, well-maintained**, and has\n",
    "some pleasant features, earning a mid-to-high score.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8d1cc1-a40f-4304-a7f0-39db8073ad92",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Ratelimits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "632f1463-31f3-4563-966a-5bf5343cc4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class RateLimiter:\n",
    "    def __init__(self, max_tokens_per_minute, max_calls_per_minute):\n",
    "        self.max_tokens_per_minute = max_tokens_per_minute\n",
    "        self.max_calls_per_minute = max_calls_per_minute\n",
    "        \n",
    "        # Tracking tokens and calls\n",
    "        self.tokens_generated = 0\n",
    "        self.calls_made = 0\n",
    "        \n",
    "        # Start times for the token and call tracking\n",
    "        self.start_time_tokens = time.perf_counter()\n",
    "        self.start_time_calls = time.perf_counter()\n",
    "        self.time_window = 60  # seconds in a minute\n",
    "\n",
    "    def _check_and_reset(self, current_time, start_time, current_count):\n",
    "        \"\"\"\n",
    "        Resets the count and start time if the time window has passed.\n",
    "        \"\"\"\n",
    "        elapsed_time = current_time - start_time\n",
    "        if elapsed_time > self.time_window:\n",
    "            return current_time, 0  # Reset start time and count\n",
    "        return start_time, current_count\n",
    "\n",
    "    def check_limit(self, tokens_used=0):\n",
    "        \"\"\"\n",
    "        Checks and enforces both token and call rate limits. If necessary, sleeps until\n",
    "        it's safe to proceed.\n",
    "        \"\"\"\n",
    "        current_time = time.perf_counter()\n",
    "\n",
    "        # Reset token and call counters if a new time window has started\n",
    "        self.start_time_tokens, self.tokens_generated = self._check_and_reset(\n",
    "            current_time, self.start_time_tokens, self.tokens_generated\n",
    "        )\n",
    "        self.start_time_calls, self.calls_made = self._check_and_reset(\n",
    "            current_time, self.start_time_calls, self.calls_made\n",
    "        )\n",
    "\n",
    "        # Increment token and call counts\n",
    "        self.tokens_generated += tokens_used\n",
    "        self.calls_made += 1\n",
    "\n",
    "        # Calculate delays for tokens\n",
    "        token_delay = 0\n",
    "        allowed_tokens = self.max_tokens_per_minute * (\n",
    "            (current_time - self.start_time_tokens) / self.time_window\n",
    "        )\n",
    "        if self.tokens_generated > allowed_tokens:\n",
    "            token_delay = (self.tokens_generated - allowed_tokens) / (\n",
    "                self.max_tokens_per_minute / self.time_window\n",
    "            )\n",
    "\n",
    "        # Calculate delays for calls\n",
    "        call_delay = 0\n",
    "        allowed_calls = self.max_calls_per_minute * (\n",
    "            (current_time - self.start_time_calls) / self.time_window\n",
    "        )\n",
    "        if self.calls_made > allowed_calls:\n",
    "            call_delay = (self.calls_made - allowed_calls) / (\n",
    "                self.max_calls_per_minute / self.time_window\n",
    "            )\n",
    "\n",
    "        # Sleep for the maximum required delay\n",
    "        if token_delay > 0 or call_delay > 0:\n",
    "            time.sleep(max(token_delay, call_delay))\n",
    "\n",
    "rate_limiter = RateLimiter(max_tokens_per_minute=4_000_000, max_calls_per_minute=4_000) # for gemini-flash-8b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113aca28-3119-44a8-b870-21d385a28b19",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Scenic value assignment to stops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a120ebc2-03fe-4dbc-94db-cf3b025f453d",
   "metadata": {},
   "source": [
    "# Running with asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7910d9da-8f9c-4e19-b602-fc3be597909c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning scenic values to stops:: 100%|██████████| 3/3 [00:14<00:00,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neighbors': {'Gustavslund': {'longitude': 18.685677, 'latitude': 59.748096, 'transport_mode': 'bus'}, 'Astrid Lindgrens gata': {'longitude': 18.685677, 'latitude': 59.748096, 'transport_mode': 'bus'}, 'Backtorp': {'longitude': 18.685677, 'latitude': 59.748096, 'transport_mode': 'bus'}, 'Norrtälje busstation': {'longitude': 18.685677, 'latitude': 59.748096, 'transport_mode': 'bus'}, 'Malsta vägskäl': {'longitude': 18.685677, 'latitude': 59.748096, 'transport_mode': 'bus'}, 'Stockholmsvägen': {'longitude': 18.685677, 'latitude': 59.748096, 'transport_mode': 'bus', 'scenic_value': (6.5, 962)}, 'Södra Lohärad': {'longitude': 18.685677, 'latitude': 59.748096, 'transport_mode': 'bus'}, 'Rösa trafikplats': {'longitude': 18.685677, 'latitude': 59.748096, 'transport_mode': 'bus'}}, 'latitude': 59.748096, 'longitude': 18.685677, 'scenic_value': (6.5, 984)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "import instructor\n",
    "import os\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ[\"GEMINI_API_KEY\"], \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n",
    "\n",
    "class ScenicValue(BaseModel):\n",
    "    scenic_value: float\n",
    "\n",
    "def assign_scenic_description(stop_name, season=\"summer\"):\n",
    "    result = client.beta.chat.completions.parse(\n",
    "        model=\"gemini-1.5-flash-8b\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Respond using a list.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"\n",
    "                Context: '{system_prompt1}'\n",
    "                \n",
    "                Meta-data: The stop name is '{stop_name}'. The current season is '{season}'.\n",
    "                \"\"\"\n",
    "            },\n",
    "        ],\n",
    "        max_tokens=500,\n",
    "        temperature=0,\n",
    "    )\n",
    "    description = result.choices[0].message.content\n",
    "    tokens_used = result.usage.total_tokens\n",
    "    return description, tokens_used\n",
    "\n",
    "\n",
    "def assign_scenic_value(descriptions):\n",
    "    result = client.beta.chat.completions.parse(\n",
    "        model=\"gemini-1.5-flash-8b\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Respond with one number with one decimal.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"\"\"\n",
    "            Instructions:\n",
    "            <instructions>\n",
    "            {system_prompt2}\n",
    "            </instructions>\n",
    "            \n",
    "            Description:\n",
    "            <descriptions>\n",
    "            {descriptions}\n",
    "            </descriptions>\n",
    "            \"\"\"},\n",
    "        ],\n",
    "        temperature=0, \n",
    "        response_format=ScenicValue,\n",
    "    )\n",
    "    scenic_value = json.loads(result.choices[0].message.content)[\"scenic_value\"]\n",
    "    tokens_used = result.usage.total_tokens\n",
    "    return scenic_value, tokens_used\n",
    "\n",
    "with open('graph_with_coordinates_and_neighbors.pickle', 'rb') as file:\n",
    "    graph = pickle.load(file)\n",
    "\n",
    "def sub_graph(data, n=2):\n",
    "    keys = list(data.keys())\n",
    "    sliced_keys = keys[:n]\n",
    "    return {key: data[key] for key in sliced_keys}\n",
    "\n",
    "graph = sub_graph(graph, n=3) # seet n = len(data) for the full dataset\n",
    "stop_names = list(graph.keys()) # A list of stops represneted as strings\n",
    "stop_scenic_values = []\n",
    "\n",
    "# Assigns scenic value for each stop\n",
    "for i, stop_name in tqdm(enumerate(stop_names), total=len(stop_names), desc=\"Assigning scenic values to stops:\"):\n",
    "    descriptions, tokens_used = assign_scenic_description(stop_name)\n",
    "    scenic_value = assign_scenic_value(descriptions)\n",
    "    #scenic_value = np.random.randint(0, 10)\n",
    "    stop_scenic_values.append({stop_name: scenic_value})\n",
    "    rate_limiter.check_limit(tokens_used=tokens_used)\n",
    "\n",
    "# Mapping the scenic values to each stops and its corresponding neighbors\n",
    "scenic_values_dict = {}\n",
    "for scenic_value in stop_scenic_values:\n",
    "    for stop, value in scenic_value.items():\n",
    "        scenic_values_dict[stop] = value\n",
    "\n",
    "for stop, info in graph.items():\n",
    "    if stop in scenic_values_dict:\n",
    "        info['scenic_value'] = scenic_values_dict[stop]\n",
    "    for neighbor, neighbor_info in info.get('neighbors', {}).items():\n",
    "        if neighbor in scenic_values_dict:\n",
    "            neighbor_info['scenic_value'] = scenic_values_dict[neighbor]\n",
    "\n",
    "print(graph[\"Campus Roslagen\"])\n",
    "with open('graph_with_scenic_values.pickle', 'wb') as file:\n",
    "    pickle.dump(graph, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5bb36e-8682-46f9-822e-9ecdfd25ad2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import math\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "from pydantic import BaseModel\n",
    "from time import perf_counter, sleep\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash-8b\")\n",
    "        \n",
    "class ScenicValue(BaseModel):\n",
    "    scenic_value: float\n",
    "\n",
    "async def assign_scenic_description(stop_name, season=\"summer\"):\n",
    "    result = await model.generate_content_async(\n",
    "        contents=[\n",
    "            \"Respond using a list.\",\n",
    "            f\"Instructions: '{system_prompt1}'\",\n",
    "            f\"Context: The stop name is '{stop_name}'. The current season is '{season}'.\"\n",
    "        ],\n",
    "        generation_config=genai.GenerationConfig(\n",
    "            max_output_tokens=500,\n",
    "            temperature=0,\n",
    "        )\n",
    "    )\n",
    "    description = result.text\n",
    "    return description\n",
    "\n",
    "async def assign_scenic_value(description):\n",
    "    result = await model.generate_content_async(\n",
    "        contents=[\n",
    "            \"Respond with one number with one decimal.\", \n",
    "            f\"Instructions: {system_prompt2}\", \n",
    "            f\"Context: {description}\"\n",
    "        ],\n",
    "        generation_config=genai.GenerationConfig(\n",
    "            response_mime_type='application/json',\n",
    "            response_schema=ScenicValue,\n",
    "            max_output_tokens=50,\n",
    "            temperature=0,\n",
    "        )\n",
    "    )\n",
    "    scenic_value = json.loads(result.text)[\"scenic_value\"]\n",
    "    return scenic_value\n",
    "\n",
    "async def evaluate(stop_name):\n",
    "    description = await assign_scenic_description(stop_name)\n",
    "    scenic_value = await assign_scenic_value(description)\n",
    "    return {stop_name: scenic_value}\n",
    "\n",
    "async def dummy_evaluate(stop_name):\n",
    "    scenic_value = np.random.randint(0, 10)\n",
    "    return {stop_name: scenic_value}\n",
    "\n",
    "def split_list_into_chunks(original_list, max_chunk_size=2000):\n",
    "    length = len(original_list)\n",
    "    num_chunks = math.ceil(length / max_chunk_size)\n",
    "    base_chunk_size = length // num_chunks\n",
    "    remainder = length % num_chunks\n",
    "\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    for i in range(num_chunks):\n",
    "        end = start + base_chunk_size + (1 if i < remainder else 0)\n",
    "        chunks.append(original_list[start:end])\n",
    "        start = end\n",
    "\n",
    "    return chunks\n",
    "\n",
    "with open('graph_with_coordinates_and_neighbors.pickle', 'rb') as file:\n",
    "    graph = pickle.load(file)\n",
    "\n",
    "def sub_graph(data, n=2):\n",
    "    keys = list(data.keys())\n",
    "    sliced_keys = keys[:n]\n",
    "    return {key: data[key] for key in sliced_keys}\n",
    "\n",
    "graph = sub_graph(graph, n=len(graph)) # set n = len(data) for the full dataset\n",
    "stop_names = list(graph.keys()) # A list of stops represented as strings\n",
    "stop_name_chunks = split_list_into_chunks(stop_names)\n",
    "stop_scenic_values = []\n",
    "\n",
    "# Creates a list of dictionaries [{stop_name: scenic_value}]\n",
    "for stop_name_chunk in stop_name_chunks:\n",
    "    tasks = [dummevaluate(stop_name) for stop_name in stop_name_chunk]\n",
    "    stop_scenic_values_chunk = await tqdm_asyncio.gather(*tasks)\n",
    "    stop_scenic_values += stop_scenic_values_chunk\n",
    "    # Saving\n",
    "    #with open('stop_scenic_values.json', 'w') as file:\n",
    "    #    json.dump(stop_scenic_values, file)\n",
    "    sleep(60)\n",
    "\n",
    "# Mapping the scenic values to each stops and its corresponding neighbors\n",
    "scenic_values_dict = {}\n",
    "for scenic_value in stop_scenic_values:\n",
    "    for stop, value in scenic_value.items():\n",
    "        scenic_values_dict[stop] = value\n",
    "\n",
    "for stop, info in graph.items():\n",
    "    if stop in scenic_values_dict:\n",
    "        info['scenic_value'] = scenic_values_dict[stop]\n",
    "    for neighbor, neighbor_info in info.get('neighbors', {}).items():\n",
    "        if neighbor in scenic_values_dict:\n",
    "            neighbor_info['scenic_value'] = scenic_values_dict[neighbor]\n",
    "\n",
    "print(graph[\"Campus Roslagen\"])\n",
    "#with open('graph_with_scenic_values.pickle', 'wb') as file:\n",
    "#    pickle.dump(graph, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a64ca4d-c9ef-41f4-8702-c95330da926f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletionUsage(completion_tokens=357, prompt_tokens=334, total_tokens=691, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "CompletionUsage(completion_tokens=352, prompt_tokens=334, total_tokens=686, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "CompletionUsage(completion_tokens=324, prompt_tokens=335, total_tokens=659, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "CompletionUsage(completion_tokens=382, prompt_tokens=335, total_tokens=717, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "CompletionUsage(completion_tokens=372, prompt_tokens=335, total_tokens=707, completion_tokens_details=None, prompt_tokens_details=None)\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(\n",
    "    api_key=os.environ[\"GEMINI_API_KEY\"], \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n",
    "\n",
    "for stop_name in ['Campus Roslagen', 'Stockholmsvägen', 'Familjens hus', 'Flygfältet', 'Ålandsgatan']:\n",
    "    season=\"summer\"\n",
    "    result = client.beta.chat.completions.parse(\n",
    "        model=\"gemini-1.5-flash-8b\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Respond using a list.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"\n",
    "                Context: '{system_prompt1}'\n",
    "                \n",
    "                Meta-data: The stop name is '{stop_name}'. The current season is '{season}'.\n",
    "                \"\"\"\n",
    "            },\n",
    "        ],\n",
    "        max_tokens=500,\n",
    "        temperature=0,\n",
    "    )\n",
    "    \n",
    "    descriptions = result.choices[0].message.content\n",
    "    print(result.usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c6d313a5-2cf8-4a02-a08f-334dc00111ea",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletionUsage(completion_tokens=14, prompt_tokens=983, total_tokens=997, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "CompletionUsage(completion_tokens=14, prompt_tokens=983, total_tokens=997, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "CompletionUsage(completion_tokens=14, prompt_tokens=983, total_tokens=997, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "CompletionUsage(completion_tokens=14, prompt_tokens=983, total_tokens=997, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "CompletionUsage(completion_tokens=14, prompt_tokens=983, total_tokens=997, completion_tokens_details=None, prompt_tokens_details=None)\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(\n",
    "    api_key=os.environ[\"GEMINI_API_KEY\"], \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n",
    "\n",
    "for _ in range(5):\n",
    "    result = client.beta.chat.completions.parse(\n",
    "        model=\"gemini-1.5-flash-8b\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Respond with one number with one decimal.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"\"\"\n",
    "            Instructions:\n",
    "            <instructions>\n",
    "            {system_prompt2}\n",
    "            </instructions>\n",
    "            \n",
    "            Description:\n",
    "            <descriptions>\n",
    "            {descriptions}\n",
    "            </descriptions>\n",
    "            \"\"\"},\n",
    "        ],\n",
    "        temperature=0, \n",
    "        max_tokens=50,\n",
    "        response_format=ScenicValue,\n",
    "    )\n",
    "    \n",
    "    print(result.usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "7da52922-4b3f-41de-af01-cde8c5f0b95d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2720800"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterations = 1432 #4295 \n",
    "input_tokens = (1000 + 350) * iterations\n",
    "output_tokens = (50 + 500) * iterations\n",
    "total_tokens = input_tokens + output_tokens\n",
    "input_price = 0.0375 * input_tokens / 1_000_000\n",
    "output_price = 0.15 * output_tokens / 1_000_000\n",
    "dollars_to_sek = 10.9\n",
    "#dollars_to_sek * (input_price + output_price)\n",
    "total_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d7460d-c62f-44de-af73-476c562e86d9",
   "metadata": {},
   "source": [
    "# A star search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "642a08af-9381-482a-a64b-78e0e14c7dc9",
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 71\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m path\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgraph_with_scenic_values.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m---> 71\u001b[0m     graph \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[1;32m     73\u001b[0m stop_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(graph\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;66;03m# A list of stops represented as strings\u001b[39;00m\n\u001b[1;32m     74\u001b[0m start_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRopsten\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m#np.random.choice(stop_names) #'Ropsten'\u001b[39;00m\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import heapq\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def haversine_distance(longitude1, latitude1, longitude2, latitude2):\n",
    "    \"\"\"\n",
    "    Calculates the Haversine distance between two points.\n",
    "\n",
    "    Args:\n",
    "    longitude1 (float): The longitude of the first point.\n",
    "    latitude1 (float): The latitude of the first point.\n",
    "    longitude2 (float): The longitude of the second point.\n",
    "    latitude2 (float): The latitude of the second point.\n",
    "\n",
    "    Returns:\n",
    "    float: The Haversine distance between the two points.\n",
    "    \"\"\"\n",
    "    R = 6371  # Radius of the Earth\n",
    "    d_longitude = math.radians(longitude2 - longitude1)\n",
    "    d_latitude = math.radians(latitude2 - latitude1)\n",
    "    a = math.sin(d_latitude / 2) ** 2 + math.cos(math.radians(latitude1)) * math.cos(math.radians(latitude2)) * math.sin(d_longitude / 2) ** 2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "def scenic_cost(scenic_value, C=0.1, lam=0.5):\n",
    "    return C * math.exp(-lam * scenic_value)\n",
    "\n",
    "def a_star_search(graph, start, goal):\n",
    "    open_list = []\n",
    "    heapq.heappush(open_list, (0, start))\n",
    "    came_from = {start: None}\n",
    "    cost_so_far = {start: 0}\n",
    "\n",
    "    while open_list:\n",
    "        current_cost, current_stop = heapq.heappop(open_list)\n",
    "\n",
    "        if current_stop == goal:\n",
    "            break\n",
    "\n",
    "        for neighbor, neighbor_info in graph[current_stop].get('neighbors', {}).items():\n",
    "            current_scenic_value = graph[current_stop].get('scenic_value', 0)\n",
    "            neighbor_scenic_value = neighbor_info.get('scenic_value', 0)\n",
    "            effective_scenic_value = (current_scenic_value + neighbor_scenic_value) / 2\n",
    "            distance = haversine_distance(\n",
    "                graph[current_stop]['longitude'], \n",
    "                graph[current_stop]['latitude'], \n",
    "                graph[neighbor]['longitude'], \n",
    "                graph[neighbor]['latitude']\n",
    "            )\n",
    "            new_cost = cost_so_far[current_stop] + distance + scenic_cost(effective_scenic_value)\n",
    "            \n",
    "            if neighbor not in cost_so_far or new_cost < cost_so_far[neighbor]:\n",
    "                cost_so_far[neighbor] = new_cost\n",
    "                priority = new_cost + haversine_distance(graph[neighbor]['longitude'], graph[neighbor]['latitude'], graph[goal]['longitude'], graph[goal]['latitude'])\n",
    "                heapq.heappush(open_list, (priority, neighbor))\n",
    "                came_from[neighbor] = current_stop\n",
    "\n",
    "    # Reconstruct the path\n",
    "    current_stop = goal\n",
    "    path = []\n",
    "    while current_stop is not None:\n",
    "        path.append(current_stop)\n",
    "        current_stop = came_from.get(current_stop)\n",
    "    path.reverse()\n",
    "    return path\n",
    "\n",
    "with open('graph_with_scenic_values.pickle', 'rb') as file:\n",
    "    graph = pickle.load(file)\n",
    "\n",
    "stop_names = list(graph.keys()) # A list of stops represented as strings\n",
    "start_stop = 'Ropsten' #np.random.choice(stop_names) #'Ropsten'\n",
    "goal_stop = 'Nybroplan' #np.random.choice(stop_names) #'Nybroplan'\n",
    "shortest_path = a_star_search(graph, start_stop, goal_stop)\n",
    "print(shortest_path)\n",
    "\n",
    "def visualize_path(graph, path):\n",
    "    # Extract all stops' data\n",
    "    all_longitudes = [graph[stop]['longitude'] for stop in graph]\n",
    "    all_latitudes = [graph[stop]['latitude'] for stop in graph]\n",
    "    all_stop_names = list(graph.keys())\n",
    "    all_scenic_values = [graph[stop].get('scenic_value', 0) for stop in graph]\n",
    "\n",
    "    # Extract the longitude, latitude, and scenic values of stops in the critical path\n",
    "    path_longitudes = [graph[stop]['longitude'] for stop in path]\n",
    "    path_latitudes = [graph[stop]['latitude'] for stop in path]\n",
    "    path_scenic_values = [graph[stop].get('scenic_value', 0) for stop in path]\n",
    "    path_stop_names = path\n",
    "\n",
    "    # Calculate the average of the start and end stop coordinates for centering the map\n",
    "    start_longitude = graph[path[0]]['longitude']\n",
    "    start_latitude = graph[path[0]]['latitude']\n",
    "    end_longitude = graph[path[-1]]['longitude']\n",
    "    end_latitude = graph[path[-1]]['latitude']\n",
    "    avg_longitude = (start_longitude + end_longitude) / 2\n",
    "    avg_latitude = (start_latitude + end_latitude) / 2\n",
    "\n",
    "    # Create a Plotly figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add all stops as markers\n",
    "    fig.add_trace(go.Scattermapbox(\n",
    "        lat=all_latitudes,\n",
    "        lon=all_longitudes,\n",
    "        mode='markers',\n",
    "        marker=go.scattermapbox.Marker(\n",
    "            size=8,\n",
    "            color='blue',  # Color for all stops\n",
    "            opacity=0.7\n",
    "        ),\n",
    "        hoverinfo='text',\n",
    "        hovertext=[f'Stop: {stop_name}<br>Scenic Value: {scenic_value}' \n",
    "                   for stop_name, scenic_value in zip(all_stop_names, all_scenic_values)],\n",
    "        name='All Stops'\n",
    "    ))\n",
    "\n",
    "    # Add critical path as a line with highlighted markers\n",
    "    fig.add_trace(go.Scattermapbox(\n",
    "        lat=path_latitudes,\n",
    "        lon=path_longitudes,\n",
    "        mode='markers+lines',\n",
    "        marker=go.scattermapbox.Marker(\n",
    "            size=10,\n",
    "            color='red',  # Color for critical path stops\n",
    "            opacity=1.0\n",
    "        ),\n",
    "        line=go.scattermapbox.Line(\n",
    "            color='red',  # Line color for critical path\n",
    "            width=3\n",
    "        ),\n",
    "        hoverinfo='text',\n",
    "        hovertext=[f'Stop: {stop_name}<br>Scenic Value: {scenic_value}' \n",
    "                   for stop_name, scenic_value in zip(path_stop_names, path_scenic_values)],\n",
    "        name='Critical Path'\n",
    "    ))\n",
    "\n",
    "    # Update the layout\n",
    "    fig.update_layout(\n",
    "        mapbox_style=\"open-street-map\",\n",
    "        mapbox_zoom=10,\n",
    "        mapbox_center_lat=avg_latitude,\n",
    "        mapbox_center_lon=avg_longitude,\n",
    "        margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0},\n",
    "        height=800\n",
    "    )\n",
    "\n",
    "    # Show the figure\n",
    "    fig.show()\n",
    "\n",
    "# Example usage:\n",
    "visualize_path(graph, shortest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5a37f2-7fb2-420b-8692-f49f0b256113",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
