{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9088c8b-be22-4cba-84a0-5a8e06abb6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1432/1432 [00:00<00:00, 67451.78it/s]\n",
      "100%|██████████| 1432/1432 [00:00<00:00, 56055.58it/s]\n",
      "100%|██████████| 1431/1431 [00:00<00:00, 46979.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neighbors': {'Gustavslund': {'longitude': 18.685677, 'latitude': 59.748096, 'transport_mode': 'bus', 'scenic_value': 7}, 'Astrid Lindgrens gata': {'longitude': 18.685677, 'latitude': 59.748096, 'transport_mode': 'bus', 'scenic_value': 4}, 'Backtorp': {'longitude': 18.685677, 'latitude': 59.748096, 'transport_mode': 'bus', 'scenic_value': 5}, 'Norrtälje busstation': {'longitude': 18.685677, 'latitude': 59.748096, 'transport_mode': 'bus', 'scenic_value': 2}, 'Malsta vägskäl': {'longitude': 18.685677, 'latitude': 59.748096, 'transport_mode': 'bus', 'scenic_value': 6}, 'Stockholmsvägen': {'longitude': 18.685677, 'latitude': 59.748096, 'transport_mode': 'bus', 'scenic_value': 5}, 'Södra Lohärad': {'longitude': 18.685677, 'latitude': 59.748096, 'transport_mode': 'bus', 'scenic_value': 4}, 'Rösa trafikplats': {'longitude': 18.685677, 'latitude': 59.748096, 'transport_mode': 'bus', 'scenic_value': 2}}, 'latitude': 59.748096, 'longitude': 18.685677, 'scenic_value': 5}\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "from pydantic import BaseModel\n",
    "from time import perf_counter, sleep\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash-8b\")\n",
    "        \n",
    "class ScenicValue(BaseModel):\n",
    "    scenic_value: float\n",
    "\n",
    "async def assign_scenic_description(stop_name, season=\"summer\"):\n",
    "    result = await model.generate_content_async(\n",
    "        contents=[\n",
    "            \"Respond using a list.\",\n",
    "            f\"Instructions: '{system_prompt1}'\",\n",
    "            f\"Context: The stop name is '{stop_name}'. The current season is '{season}'.\"\n",
    "        ],\n",
    "        generation_config=genai.GenerationConfig(\n",
    "            max_output_tokens=500,\n",
    "            temperature=0,\n",
    "        )\n",
    "    )\n",
    "    description = result.text\n",
    "    return description\n",
    "\n",
    "async def assign_scenic_value(description):\n",
    "    result = await model.generate_content_async(\n",
    "        contents=[\n",
    "            \"Respond with one number with one decimal.\", \n",
    "            f\"Instructions: {system_prompt2}\", \n",
    "            f\"Context: {description}\"\n",
    "        ],\n",
    "        generation_config=genai.GenerationConfig(\n",
    "            response_mime_type='application/json',\n",
    "            response_schema=ScenicValue,\n",
    "            max_output_tokens=50,\n",
    "            temperature=0,\n",
    "        )\n",
    "    )\n",
    "    scenic_value = json.loads(result.text)[\"scenic_value\"]\n",
    "    return scenic_value\n",
    "\n",
    "async def evaluate(stop_name):\n",
    "    description = await assign_scenic_description(stop_name)\n",
    "    scenic_value = await assign_scenic_value(description)\n",
    "    return {stop_name: scenic_value}\n",
    "\n",
    "async def dummy_evaluate(stop_name):\n",
    "    scenic_value = np.random.randint(0, 10)\n",
    "    return {stop_name: scenic_value}\n",
    "\n",
    "def split_list_into_chunks(original_list, max_chunk_size=2000):\n",
    "    length = len(original_list)\n",
    "    num_chunks = math.ceil(length / max_chunk_size)\n",
    "    base_chunk_size = length // num_chunks\n",
    "    remainder = length % num_chunks\n",
    "\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    for i in range(num_chunks):\n",
    "        end = start + base_chunk_size + (1 if i < remainder else 0)\n",
    "        chunks.append(original_list[start:end])\n",
    "        start = end\n",
    "\n",
    "    return chunks\n",
    "\n",
    "with open('graph_with_coordinates_and_neighbors.pickle', 'rb') as file:\n",
    "    graph = pickle.load(file)\n",
    "\n",
    "def sub_graph(data, n=2):\n",
    "    keys = list(data.keys())\n",
    "    sliced_keys = keys[:n]\n",
    "    return {key: data[key] for key in sliced_keys}\n",
    "\n",
    "graph = sub_graph(graph, n=len(graph)) # set n = len(data) for the full dataset\n",
    "stop_names = list(graph.keys()) # A list of stops represented as strings\n",
    "stop_name_chunks = split_list_into_chunks(stop_names)\n",
    "stop_scenic_values = []\n",
    "\n",
    "# Creates a list of dictionaries [{stop_name: scenic_value}]\n",
    "for stop_name_chunk in stop_name_chunks:\n",
    "    tasks = [evaluate(stop_name) for stop_name in stop_name_chunk]\n",
    "    stop_scenic_values_chunk = await tqdm_asyncio.gather(*tasks)\n",
    "    stop_scenic_values += stop_scenic_values_chunk\n",
    "    # Saving\n",
    "    with open('stop_scenic_values.json', 'w') as file:\n",
    "        json.dump(stop_scenic_values, file)\n",
    "    sleep(60)\n",
    "\n",
    "# Mapping the scenic values to each stops and its corresponding neighbors\n",
    "scenic_values_dict = {}\n",
    "for scenic_value in stop_scenic_values:\n",
    "    for stop, value in scenic_value.items():\n",
    "        scenic_values_dict[stop] = value\n",
    "\n",
    "for stop, info in graph.items():\n",
    "    if stop in scenic_values_dict:\n",
    "        info['scenic_value'] = scenic_values_dict[stop]\n",
    "    for neighbor, neighbor_info in info.get('neighbors', {}).items():\n",
    "        if neighbor in scenic_values_dict:\n",
    "            neighbor_info['scenic_value'] = scenic_values_dict[neighbor]\n",
    "\n",
    "print(graph[\"Campus Roslagen\"])\n",
    "with open('graph_with_scenic_values.pickle', 'wb') as file:\n",
    "    pickle.dump(graph, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b230e24c-8364-487a-9086-85e4bfd82e3e",
   "metadata": {},
   "source": [
    "# Creating the graph from csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "389dcb53-9ab4-4462-b3c6-48a1f0a6c00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66131/66131 [01:34<00:00, 702.99it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Stop: Alvik\n",
      "  Latitude: 59.333385, Longitude: 17.98016\n",
      "  Neighbors:\n",
      "    -> Tranebergsplan: {'bus': 65.4416135881104}\n",
      "    -> Alviksvägen: {'bus': 120.8135593220339}\n",
      "    -> Alléparken: {'tram': 60.0, 'bus': 104.5}\n",
      "    -> Kristineberg: {'metro': 120.0}\n",
      "    -> Stora mossen: {'metro': 120.0}\n",
      "    -> Johannesfred: {'tram': 180.0, 'bus': 387.90697674418607}\n",
      "    -> Alviks strand: {'tram': 105.0}\n",
      "    -> Lintavägen: {'bus': 392.3720930232558}\n"
     ]
    }
   ],
   "source": [
    "# Santosh scraped data from SL API and constructed 'routes_master_data.csv'\n",
    "# Wenhan wrote the code in this code cell\n",
    "# Erik contributed to debugging\n",
    "import math\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "def time_to_seconds(time_str):\n",
    "    \"\"\"\n",
    "    Converts a 'HH:MM:SS' string into seconds after midnight (integer).\n",
    "    Returns None if the input is invalid (NaN or None).\n",
    "    \"\"\"\n",
    "    if not time_str or pd.isna(time_str):\n",
    "        return None\n",
    "    \n",
    "    hh, mm, ss = time_str.split(\":\")\n",
    "    return int(hh) * 3600 + int(mm) * 60 + int(ss)\n",
    "\n",
    "def build_traffic_graph(csv_path):\n",
    "    \"\"\"\n",
    "    Build a graph from the routes_master_data CSV.\n",
    "    Scenic values are intentionally excluded from this graph.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the graph\n",
    "    graph = {}\n",
    "\n",
    "    # Read the CSV into a DataFrame\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Group by Route, Direction, Journey for consecutive stops\n",
    "    grouped = df.groupby([\"Route_ID\", \"Direction\", \"Journey_ID\"], dropna=False)\n",
    "    \n",
    "    for _, group in tqdm(grouped):\n",
    "        # Sort by 'Order'\n",
    "        group_sorted = group.sort_values(\"Order\", ascending=True)\n",
    "        group_sorted = group_sorted.dropna(subset=[\"StopPlace Name\"]).reset_index(drop=True)\n",
    "\n",
    "        for i in range(len(group_sorted) - 1):\n",
    "            from_stop = group_sorted.loc[i, \"StopPlace Name\"]\n",
    "            to_stop = group_sorted.loc[i + 1, \"StopPlace Name\"]\n",
    "\n",
    "            mode = group_sorted.loc[i, \"TransportMode\"]\n",
    "            if pd.isna(mode):\n",
    "                mode = \"unknown\"\n",
    "\n",
    "            dep_time_str = group_sorted.loc[i, \"DepartureTime\"]\n",
    "            arr_time_str = group_sorted.loc[i + 1, \"ArrivalTime\"]\n",
    "            dep_sec = time_to_seconds(dep_time_str)\n",
    "            arr_sec = time_to_seconds(arr_time_str)\n",
    "\n",
    "            # ---------------------------\n",
    "            # Handle potential day rollover\n",
    "            # ---------------------------\n",
    "            travel_time = None\n",
    "            if dep_sec is not None and arr_sec is not None:\n",
    "                # If arrival second-of-day is *earlier*, assume next day\n",
    "                if arr_sec < dep_sec:\n",
    "                    arr_sec += 24 * 3600  # Add 24 hours in seconds\n",
    "\n",
    "                travel_time = arr_sec - dep_sec\n",
    "\n",
    "            # Fetch latitude/longitude\n",
    "            from_lat = group_sorted.loc[i, \"StopPlace Latitude\"]\n",
    "            from_lon = group_sorted.loc[i, \"StopPlace Longitude\"]\n",
    "            to_lat = group_sorted.loc[i + 1, \"StopPlace Latitude\"]\n",
    "            to_lon = group_sorted.loc[i + 1, \"StopPlace Longitude\"]\n",
    "\n",
    "            # Initialize nodes if needed\n",
    "            if from_stop not in graph:\n",
    "                graph[from_stop] = {\n",
    "                    \"latitude\": from_lat,\n",
    "                    \"longitude\": from_lon,\n",
    "                    \"neighbors\": {}\n",
    "                }\n",
    "            if to_stop not in graph:\n",
    "                graph[to_stop] = {\n",
    "                    \"latitude\": to_lat,\n",
    "                    \"longitude\": to_lon,\n",
    "                    \"neighbors\": {}\n",
    "                }\n",
    "\n",
    "            # Initialize or update the edge\n",
    "            if to_stop not in graph[from_stop][\"neighbors\"]:\n",
    "                graph[from_stop][\"neighbors\"][to_stop] = {}\n",
    "\n",
    "            # Ensure the mode key is present\n",
    "            if mode not in graph[from_stop][\"neighbors\"][to_stop]:\n",
    "                graph[from_stop][\"neighbors\"][to_stop][mode] = []\n",
    "\n",
    "            # Append travel time\n",
    "            if travel_time is not None:\n",
    "                graph[from_stop][\"neighbors\"][to_stop][mode].append(travel_time)\n",
    "\n",
    "    # Compute average (mean) travel times\n",
    "    for from_stop, data in graph.items():\n",
    "        for to_stop, edge_data in data[\"neighbors\"].items():\n",
    "            for mode, times_list in edge_data.items():\n",
    "                if isinstance(times_list, list):  # Only process if it is a list\n",
    "                    edge_data[mode] = sum(times_list) / len(times_list) if times_list else None\n",
    "\n",
    "    return graph\n",
    "\n",
    "\n",
    "# Path to the CSV\n",
    "csv_path = \"routes_master_data.csv\"\n",
    "\n",
    "# Build the graph without scenic values\n",
    "graph = build_traffic_graph(csv_path)\n",
    "with open(\"graph.pickle\", \"wb\") as file:\n",
    "    pickle.dump(graph, file)\n",
    "    \n",
    "# Print a single sample stop to verify\n",
    "for i, (src_stop, data) in enumerate(graph.items()):\n",
    "    print(f\"Sample Stop: {src_stop}\")\n",
    "    print(f\"  Latitude: {data['latitude']}, Longitude: {data['longitude']}\")\n",
    "    print(\"  Neighbors:\")\n",
    "    for dst_stop, edge_data in data[\"neighbors\"].items():\n",
    "        print(f\"    -> {dst_stop}: {edge_data}\")\n",
    "    break  # Display only the first stop and its neighbors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
