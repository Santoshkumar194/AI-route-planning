{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59f22fa6-91dc-4970-a89b-000da500fd46",
   "metadata": {},
   "source": [
    "# One at the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b9088c8b-be22-4cba-84a0-5a8e06abb6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neighbors': {'Källvägen': {'travel_time': 1168.0,\n",
       "   'route_name': 'Bagarmossen',\n",
       "   'transport_mode': 'bus'},\n",
       "  'Murklevägen': {'travel_time': 1780.0,\n",
       "   'route_name': 'Gröndal',\n",
       "   'transport_mode': 'bus'}},\n",
       " 'stop_latitude': 59.280605,\n",
       " 'stop_longitude': 18.08223,\n",
       " 'arrival_time': '07:03:02',\n",
       " 'departure_time': '07:03:02',\n",
       " 'transport_mode': 'bus',\n",
       " 'scenic_value': (7.1, 0.2898275349237886)}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import pickle\n",
    "from time import sleep, perf_counter\n",
    "load_dotenv()\n",
    "\n",
    "with open(\"graph_simplified_id.pickle\", \"rb\") as f:\n",
    "    G = pickle.load(f)\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ[\"GEMINI_API_KEY\"],\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n",
    "\n",
    "class ScenicValue(BaseModel):\n",
    "    scenic_value: float\n",
    "\n",
    "def assign_scenic_value(stop_data, n=5):\n",
    "    \"\"\"\n",
    "    Assigns a 'scenic_value' to the stop_data using an LLM.\n",
    "    \n",
    "    Parameters:\n",
    "    stop_data (dict): The dictionary containing stop information.\n",
    "    \n",
    "    Returns:\n",
    "    dict: The updated dictionary with the 'scenic_value' key added.\n",
    "    \"\"\"\n",
    "    stop_name = next(iter(stop_data))  # Assuming stop_data is {stop_name: {...}}\n",
    "    neighbors = stop_data[stop_name].get('neighbors', {})\n",
    "    neighbor_names = list(neighbors.keys())\n",
    "    \n",
    "    result = client.beta.chat.completions.parse(\n",
    "        model=\"gemini-1.5-flash\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You provide scenic values between 0 and 10 for stops in Stockholm.\"},\n",
    "            {\"role\": \"user\", \"content\": (\n",
    "                \"I am trying to assess the scenic value of a stop in Stockholm.\"\n",
    "                f\"The stop name is '{stop_name}' and it has neighbors: {neighbor_names}.\"\n",
    "                \"Please provide a scenic value between 0 and 10 for the stop.\"\n",
    "                \"A scenic value of 5 means intuitively this place is average and does not evoke any positive or negative emotions.\"\n",
    "                \"Assume that the joy of a place is normally distirbuted according to N(5, 2),\" \n",
    "                \"meaning that a place with scenic value 9 is better than 95% of the places.\"\n",
    "            )},\n",
    "        ],\n",
    "        n=n,\n",
    "        temperature=2,\n",
    "        response_format=ScenicValue,\n",
    "    )\n",
    "\n",
    "    scenic_values = [json.loads(s.message.content)[\"scenic_value\"] for s in result.choices] # list of scenic values: [7.1, 7.1, 7, 7.5, 7.6]\n",
    "    G[stop_name][\"scenic_value\"] = (np.mean(scenic_values), np.std(scenic_values)) # assigns the stop dictionary with a 'scenic_value' tuple\n",
    "\n",
    "\n",
    "# Process a single stop (for demonstration)\n",
    "stop_name = \"Stockholmsvägen\"\n",
    "stop_data = {stop_name: G[stop_name]}\n",
    "assign_scenic_value(stop_data)\n",
    "G[stop_name]\n",
    "\n",
    "# To process all stops, iterate over the graph:\n",
    "#for stop_name in G:\n",
    "#    start_time = perf_counter()\n",
    "#    stop_data = {stop_name: G[stop_name]}\n",
    "#    assign_scenic_value(stop_data)\n",
    "\n",
    "    # Rate limiting: ensure 4 seconds between requests\n",
    "#    elapsed = perf_counter() - start_time\n",
    "#    sleep(max(4 - elapsed, 0))\n",
    "\n",
    "# Save the updated graph\n",
    "#with open(\"graph_with_scenic_values.pickle\", \"wb\") as f:\n",
    "#    pickle.dump(G, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873b316e-06a8-45df-9688-196dee7f86c1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Batched (does not work yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a75d0300-2b9d-41c0-a527-8e2675ac0d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/543 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1/543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/543 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<string>, line 2)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3577\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[142], line 97\u001b[0m\n    scenic_values = assign_scenic_values_batch(batch_stops)\u001b[0m\n",
      "\u001b[0;36m  Cell \u001b[0;32mIn[142], line 76\u001b[0;36m in \u001b[0;35massign_scenic_values_batch\u001b[0;36m\n\u001b[0;31m    response_content = eval(raw_content)\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m<string>:2\u001b[0;36m\u001b[0m\n\u001b[0;31m    import random\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Tuple, Dict, List\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pickle\n",
    "import math\n",
    "from time import perf_counter, sleep\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Load the graph from a pickle file\n",
    "with open(\"graph_simplified_id.pickle\", \"rb\") as f:\n",
    "    G = pickle.load(f)\n",
    "\n",
    "# Initialize the OpenAI client with the API key\n",
    "client = OpenAI(\n",
    "    api_key=os.environ[\"GEMINI_API_KEY\"],\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n",
    "\n",
    "# Update the Pydantic model to validate a dictionary instead of a tuple\n",
    "class ScenicValue(BaseModel):\n",
    "    scenic_values: List[float]\n",
    "\n",
    "def assign_scenic_values_batch(batch_stops):\n",
    "    \"\"\"\n",
    "    Assigns 'scenic_value' to a batch of stops using an LLM.\n",
    "    \n",
    "    Parameters:\n",
    "    batch_stops (list): A list of tuples containing stop names and their information.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary with stop names as keys and scenic values as values.\n",
    "    \"\"\"\n",
    "    # Prepare the prompt for the batch of stops\n",
    "    batch_input = []\n",
    "    for stop_name, stop_info in batch_stops:\n",
    "        neighbors = stop_info.get('neighbors', {})\n",
    "        neighbor_names = list(neighbors.keys())\n",
    "        batch_input.append({\n",
    "            \"stop_name\": stop_name,\n",
    "            \"neighbors\": neighbor_names\n",
    "        })\n",
    "    \n",
    "    prompt_content = (\n",
    "        \"You will assess the scenic value of multiple stops in Stockholm. \"\n",
    "        \"For each stop, provide a scenic value between 0 and 10 based on the stop's name and its neighbors. \"\n",
    "        \"A scenic value of 5 means the place is average and does not evoke any positive or negative emotions. \"\n",
    "        \"Assume that the joy of a place is normally distributed as N(5, 2). \"\n",
    "        \"\\nRespond with a dictionary where keys are stop names and values are their scenic values.\\n\\n\"\n",
    "        \"Here is the list of stops and their neighbors:\\n\" +\n",
    "        \"\\n\".join([f\"{item['stop_name']}: {item['neighbors']}\" for item in batch_input]) +\n",
    "        \"\\n\\nRespond with a list in the format: \"\n",
    "        \"[value1, value2, ...]. \"\n",
    "        \"The response MUST contain exactly one entry for each provided stop.\"\n",
    "    )\n",
    "    \n",
    "    # Make the API call\n",
    "    result = client.chat.completions.create(\n",
    "        model=\"gemini-1.5-flash-8b\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You provide scenic values between 0 and 10 for stops in Stockholm.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt_content},\n",
    "        ],\n",
    "        temperature=1,\n",
    "    )\n",
    "    \n",
    "    # Get the content from the first choice\n",
    "    raw_content = result.choices[0].message.content\n",
    "    raw_content = raw_content.strip().strip('```json').strip('```')\n",
    "\n",
    "    # Convert string dictionary representation to actual dictionary\n",
    "    response_content = eval(raw_content)\n",
    "    validated_response = ScenicValue(scenic_values=response_content)\n",
    "    \n",
    "    # Check that all stops are included in the response\n",
    "    batch_stop_names = {stop[0] for stop in batch_stops}\n",
    "    if set(validated_response.scenic_values.keys()) != batch_stop_names:\n",
    "        raise ValueError(\"Received scenic values for different stops than expected\")\n",
    "    \n",
    "    return validated_response.scenic_values\n",
    "\n",
    "    \n",
    "# Process all stops using batching\n",
    "batch_size = 10  # Adjust this size based on API input constraints\n",
    "stops = list(G.items())\n",
    "total_batches = math.ceil(len(stops) / batch_size)\n",
    "\n",
    "for i in tqdm(range(total_batches)):\n",
    "    start_time = perf_counter()\n",
    "    \n",
    "    print(f\"Processing batch {i+1}/{total_batches}\")\n",
    "    batch_stops = stops[i*batch_size:(i+1)*batch_size]\n",
    "    scenic_values = assign_scenic_values_batch(batch_stops)\n",
    "    \n",
    "    # Update the graph with the scenic values\n",
    "    for stop_name, value in scenic_values.items():\n",
    "        G[stop_name][\"scenic_value\"] = value\n",
    "    \n",
    "    # Rate limiting: ensure 4 seconds between requests\n",
    "    elapsed = perf_counter() - start_time\n",
    "    sleep(max(4 - elapsed, 0))\n",
    "\n",
    "# Save the updated graph\n",
    "with open(\"graph_with_scenic_values.pickle\", \"wb\") as f:\n",
    "    pickle.dump(G, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
